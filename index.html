<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta http-equiv="Content-Style-Type" content="text/css">
  <title></title>
  <meta name="Generator" content="Cocoa HTML Writer">
  <meta name="CocoaVersion" content="2113.6">
  <style type="text/css">
    p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #000000}
    p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #000000; min-height: 14.0px}
    span.s1 {font-kerning: none}
  </style>
</head>
<body>
<p class="p1"><span class="s1">
  Software Developer:<br>
  Worked with managerial staff to discover business inefficiencies.<br>
  Helped develop supply chain algorithms to automate decision making.<br>
  Converting orders to physical instructions for factory staff.<br>
  <br>
  Fullstack Development:<br>
  Used DigitalOcean to setup an SQL server. Made use of Express.js, Node.js for web server communications. Used Android Studio for UI. Users could register, login and leave reviews with a properly encrypted backend.<br>
  Github: https://github.com/AriEncarnacion/SAEGG-Game-Utility<br>
  <br>
  Machine Learning Research Assistant:<br>
  Created an algorithm for accurate Mel spectrogram classification taking home first place in the 35th Annual CSU Systemwide Student Research Competition.<br>
  The algorithm made use of Transfer Learning, CNNs, UMAP, and SVMs utilizing confidence intervals for analysis in the field of ecoinformatics.<br>
  I made a video accompanying my presentation: https://www.youtube.com/watch?v=Bpxb_7Mmx5U<br>
  <br>
  Graduated Sonoma State University with a Major GPA of 3.65 with Awards of the Dean’s List and KORET Scholar’s Award.<br>
  Currently attending UC Davis for my masters degree.<br>
  <br>
  Reinforcement Learning:<br>
  Self studied reinforcement learning DQNs and branching models to create an AI to beat a hardcoded AI.<br>
  The game was a made up card game, in which a player has to find a good balance between attacking and defending while taking risks. The hardcoded AI played an aggressive, almost optimal style that had a non-trivial weakness to be discovered. Some games are impossible to beat this strategy due to card draw.<br>
  Made use of both a base DQN and C51 agent to play in various environments.<br>
  Environments ranged from easy to hard hardcoded bots as well as other gym environments to train agents on making optimal moves.<br>
  Optimizations were made in the featurespace, as to only allow the agent to make specific “obvious” optimal plays while still giving it the agency to play the game how it wants.<br>
  The agent trained on a gym environment on average beat the hardcoded AI I had originally made.<br>
  Github: https://github.com/AlexDewey/ReinforcementLearningCardGame<br>
  <br>
  Recommendation Systems:<br>
  My first look into recommendation systems was the implementation of Joint Neural Collaborative Filtering for Recommender Systems https://arxiv.org/pdf/1907.03459.pdf<br>
  This was incredibly fun and got me into the path of reading research papers and understanding them to a deep level as I implemented the paper here https://github.com/AlexDewey/JNCF-Recommender<br>
  This experience is my first in exploring the domain space of recommender systems, I want to learn a lot more as I find them enjoyable to work on and incredibly important for many companies.<br>
  <br>
  In learning the fundamentals of recommendation systems I used basic mathematical resources to reconstruct ALS MF from scratch. This helped sharped my mathematical understanding of linear algebra and optimization theory and was the first time I focused on code quality and readability. https://github.com/AlexDewey/Matrix-Factorization-ALS<br>

</span></p>
</body>
</html>