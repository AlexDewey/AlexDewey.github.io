<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta http-equiv="Content-Style-Type" content="text/css">
  <title></title>
  <meta name="Generator" content="Cocoa HTML Writer">
  <meta name="CocoaVersion" content="2113.6">
  <style type="text/css">
    p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #000000}
    p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #000000; min-height: 14.0px}
    span.s1 {font-kerning: none}
  </style>
</head>
<body>
<p class="p1"><span class="s1">Reinforcement Learning:</span></p>
<p class="p1"><span class="s1">Self studied reinforcement learning DQNs and branching models to create an AI to beat a hardcoded AI.</span></p>
<p class="p1"><span class="s1">The game was a made up card game, in which a player has to find a good balance between attacking and defending while taking risks. The hardcoded AI played an aggressive, almost optimal style that had a non-trivial weakness to be discovered. Some games are impossible to beat this strategy due to card draw.</span></p>
<p class="p1"><span class="s1">Made use of both a base DQN and C51 agent to play in various environments.</span></p>
<p class="p1"><span class="s1">Environments ranged from easy to hard hardcoded bots as well as other gym environments to train agents on making optimal moves.</span></p>
<p class="p1"><span class="s1">Optimizations were made in the featurespace, as to only allow the agent to make specific “obvious” optimal plays while still giving it the agency to play the game how it wants.</span></p>
<p class="p1"><span class="s1">The agent trained on a gym environment on average beat the hardcoded AI I had originally made.</span></p>
<p class="p1"><span class="s1">Github: https://github.com/AlexDewey/ReinforcementLearningCardGame</span></p>
<p class="p2"><span class="s1"></span><br></p>
<p class="p1"><span class="s1">Machine Learning Research Assistant:</span></p>
<p class="p1"><span class="s1">Created an algorithm for accurate Mel spectrogram classification taking home first place in the 35th Annual CSU Systemwide Student Research Competition.</span></p>
<p class="p1"><span class="s1">The algorithm made use of Transfer Learning, CNNs, UMAP, and SVMs utilizing confidence intervals for analysis in the field of ecoinformatics.</span></p>
<p class="p1"><span class="s1">I made a video accompanying my presentation: https://www.youtube.com/watch?v=Bpxb_7Mmx5U</span></p>
<p class="p2"><span class="s1"></span><br></p>
<p class="p1"><span class="s1">Software Developer:</span></p>
<p class="p1"><span class="s1">Worked with managerial staff to discover business inefficiencies.</span></p>
<p class="p1"><span class="s1">Helped develop supply chain algorithms to automate decision making.</span></p>
<p class="p1"><span class="s1">Converting orders to physical instructions for factory staff.</span></p>
<p class="p2"><span class="s1"></span><br></p>
<p class="p1"><span class="s1">Fullstack Development:</span></p>
<p class="p1"><span class="s1">Used DigitalOcean to setup an SQL server. Made use of Express.js, Node.js for web server communications. Used Android Studio for UI. Users could register, login and leave reviews with a properly encrypted backend.</span></p>
<p class="p1"><span class="s1">Github: https://github.com/AriEncarnacion/SAEGG-Game-Utility</span></p>
<p class="p2"><span class="s1"></span><br></p>
<p class="p1"><span class="s1">Graduated Sonoma State University with a Major GPA of 3.65 with Awards of the Dean’s List and KORET Scholar’s Award.</span></p>
<p class="p1"><span class="s1">Currently attending UC Davis for my masters degree.</span></p>
<p class="p2"><span class="s1"></span><br></p>
</body>
</html>
